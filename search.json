[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the Archive",
    "section": "",
    "text": "This is the central repository for my academic work.\n\nRecent Updates\n\nAssignment 1: Human Activity Recognition\n\nUse the sidebar to navigate specific tasks.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "Human Activity Recognition/my-code/Task1.html",
    "href": "Human Activity Recognition/my-code/Task1.html",
    "title": "Task 1: Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "In data science, EDA (Exploratory Data Analysis) is the crucial first step of analyzing datasets to discover patterns, spot anomalies, test hypotheses, and check assumptions, primarily using visualizations and summary statistics, to understand the data’s core characteristics before formal modeling. It’s the detective work that helps data scientists grasp the data’s structure, identify errors, and decide how to best manipulate it for accurate insights, guiding feature selection and model building.",
    "crumbs": [
      "Assignment 1 : HAR",
      "Task 1: Exploratory Data Analysis (EDA)"
    ]
  },
  {
    "objectID": "Human Activity Recognition/my-code/Task1.html#what-is-eda",
    "href": "Human Activity Recognition/my-code/Task1.html#what-is-eda",
    "title": "Task 1: Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "In data science, EDA (Exploratory Data Analysis) is the crucial first step of analyzing datasets to discover patterns, spot anomalies, test hypotheses, and check assumptions, primarily using visualizations and summary statistics, to understand the data’s core characteristics before formal modeling. It’s the detective work that helps data scientists grasp the data’s structure, identify errors, and decide how to best manipulate it for accurate insights, guiding feature selection and model building.",
    "crumbs": [
      "Assignment 1 : HAR",
      "Task 1: Exploratory Data Analysis (EDA)"
    ]
  },
  {
    "objectID": "Human Activity Recognition/my-code/Task1.html#question-1-plot-waveforms-for-each-activity-class",
    "href": "Human Activity Recognition/my-code/Task1.html#question-1-plot-waveforms-for-each-activity-class",
    "title": "Task 1: Exploratory Data Analysis (EDA)",
    "section": "Question 1: Plot waveforms for each activity class",
    "text": "Question 1: Plot waveforms for each activity class\nPlot the waveform for one sample data from each activity class. Analyze differences/similarities between the activities.\n\n\nCode\nimport sys\nsys.path.append('..')\nfrom Assignment.HAR.MakeDataset import X_train, y_train\n\n# import os \nimport matplotlib.pyplot as plt\nimport numpy as np\n\nActivity_Classes = {1:'WALKING', 2:'WALKING_UPSTAIRS', 3:'WALKING_DOWNSTAIRS', 4:'SITTING', 5:'STANDING', 6:'LAYING'}\n\n# X_train is 3D array: (# samples = (#activity x #subjects), # timesteps, # features = (3 : accx, accy, accz))\n# we have 21 subjects for train data and 9 subjects for test data\n# 6 activities\n\n# X_train.shape = 21*6, 500, 3\n\n# print(X_train.shape)\n# open('X_train.txt', 'w').write(str(X_train))\n\n\n\nWill plot acc data on y and time steps on x axis\nData is SHUFFLED by train_test_split, so we need to use y_train to find samples by activity\n\n\n\nCode\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 8), sharex=True, sharey=True)\nt = np.linspace(0, 10, 500)\n\nfor cnt, (label_id, label_name) in enumerate(Activity_Classes.items()):\n    axis = axes[cnt // 3, cnt % 3]\n    \n    # find first sample with this activity label\n    idx = np.where(y_train == label_id)[0][0]\n    \n    x_axis = X_train[idx, :, 0]\n    y_axis = X_train[idx, :, 1]\n    z_axis = X_train[idx, :, 2]\n    \n    axis.plot(t, x_axis, label=\"accx\")\n    axis.plot(t, y_axis, label=\"accy\")\n    axis.plot(t, z_axis, label=\"accz\")\n    axis.set_title(label_name)\n    axis.legend(loc='upper right', fontsize='small')\n\nplt.tight_layout()\nplt.show()\n\n\nX_train shape: (126, 500, 3)\ny_train shape: (126,)\n\n\n\n\n\n\n\n\n\n\nObservations:\nDifferences: - Static activities (SITTING, STANDING, LAYING): Show relatively flat, stable signals with minimal fluctuation - Dynamic activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS): Show periodic oscillating patterns due to repetitive motion\nSimilarities: - All static activities have similar low-variance patterns, making them harder to distinguish from each other - Walking activities all show periodic patterns but with different frequencies and amplitudes\nCan the model classify activities? - Yes, the model should be able to distinguish between static and dynamic activities easily due to clear differences in variance/amplitude - Distinguishing between different walking activities (upstairs vs downstairs) may be more challenging as patterns are similar - Distinguishing between static activities (sitting vs standing vs laying) may also be challenging",
    "crumbs": [
      "Assignment 1 : HAR",
      "Task 1: Exploratory Data Analysis (EDA)"
    ]
  },
  {
    "objectID": "Human Activity Recognition/my-code/Task1.html#question-2-do-you-think-we-need-a-machine-learning-model-to-differentiate-between-static-activities-and-dynamic-activities",
    "href": "Human Activity Recognition/my-code/Task1.html#question-2-do-you-think-we-need-a-machine-learning-model-to-differentiate-between-static-activities-and-dynamic-activities",
    "title": "Task 1: Exploratory Data Analysis (EDA)",
    "section": "Question 2: Do you think we need a machine learning model to differentiate between static activities and dynamic activities?",
    "text": "Question 2: Do you think we need a machine learning model to differentiate between static activities and dynamic activities?\n\n\nCode\n# linear acceleration\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 8), sharex=True, sharey=True)\nt = np.linspace(0, 10, 500)\n\nfor cnt, (label_id, label_name) in enumerate(Activity_Classes.items()):\n    axis = axes[cnt // 3, cnt % 3]\n    \n    # find first sample with this activity label\n    idx = np.where(y_train == label_id)[0][0]\n    \n    x_axis = X_train[idx, :, 0]\n    y_axis = X_train[idx, :, 1]\n    z_axis = X_train[idx, :, 2]\n\n    axis.plot(t, np.sqrt(x_axis**2+y_axis**2+z_axis**2), label=\"linear acc\")\n    axis.set_title(label_name)\n    axis.legend(loc='upper right', fontsize='small')",
    "crumbs": [
      "Assignment 1 : HAR",
      "Task 1: Exploratory Data Analysis (EDA)"
    ]
  },
  {
    "objectID": "Human Activity Recognition/my-code/Task1.html#ans",
    "href": "Human Activity Recognition/my-code/Task1.html#ans",
    "title": "Task 1: Exploratory Data Analysis (EDA)",
    "section": "Ans:",
    "text": "Ans:\nNo, we don’t need a machine learning model to differentiate between static and dynamic activities.\nJustification: - For static activities , the total acceleration magnitude \\(\\sqrt{acc_x^2 + acc_y^2 + acc_z^2} \\approx 1g\\) and remains nearly constant (low variance), because the accelerometer only measures the acc due to gravity at stationary state\n\nFor dynamic activities, the magnitude oscillates significantly (high variance)\n\nA simple threshold-based rule on variance or standard deviation can reliably classify:\nif std(total_acc) &gt; threshold = Dynamic, else = Static",
    "crumbs": [
      "Assignment 1 : HAR",
      "Task 1: Exploratory Data Analysis (EDA)"
    ]
  },
  {
    "objectID": "Human Activity Recognition/my-code/Task1.html#question-3-visualize-the-data-using-pca",
    "href": "Human Activity Recognition/my-code/Task1.html#question-3-visualize-the-data-using-pca",
    "title": "Task 1: Exploratory Data Analysis (EDA)",
    "section": "Question 3: Visualize the data using PCA",
    "text": "Question 3: Visualize the data using PCA\nUse Three methods for extracting important features - PCA on Tot_Acc, using TSFEL lib and then PCA, PCA on features provided by guys who made dataset itself :)\n\\(accx^2 + accy^2 + accz^2 = Signal Energy\\) (for magnitude we need sqrt)\n\n1. PCA on Tot_Acc\n\nPCA on Total Acceleration: To compress the acceleration time series into 2 features (dimensions).\nPCA on the total Acc\n\nThere is 1 data sample (one recording window) of a person doing a single activity. This single sample contains 500 time steps (dimensions).\nIf we compress these 500 time steps down to 2 Principal Components (coordinates) \\(\\rightarrow\\) we get 2 numbers (\\(x, y\\)) that represent that entire recording.\nThis helps the human eye find patterns in a scatter plot.\n\nCorrection: It’s not that we had “500 dots” before. It is that we had 1 dot existing in a 500-dimensional invisible space. We physically cannot see 500 dimensions.\n\nBy compressing it to 2 dimensions, we can now project that 1 dot onto a flat 2D screen. This allows us to check if the “dots” for static activities (Sitting) are visibly separated from the “dots” for dynamic activities (Walking).\nSo this helps in EDA.\n\n\nMethod: - Standardization (\\(\\mu=0, \\sigma=1\\)) - Covariance Matrix - Find Eigen Values and Vectors - Sort and Select Comps - Project the new onto new subspace (tranoformation \\(Y=XW\\))\n\nAS we need to look at scatter plot for all activities we need a a shared coordinate system, so we dont have to do PCA for each activity, we need to convert whole dataset to new system of 2 features.\n\n\n\nCode\n# using covaraiance matrix method as above is not used in data analysis bcz calculating covariance matrix for large datasets is computationally expensive and may not be feasible for real-time applications.\n# so we use sklearn lib, which uses SVD method internally to compute principal components efficiently. wihtout needing the space and time complexity of covariance matrix calculation.\n\nfrom sklearn.decomposition import PCA\n\nsquared = X_train**2\nX_energy = np.sum(squared, axis=2) # axis=2 means summing along the feature axis (accx, accy, accz), as its zero based indexing 0,1,2\n\n\n# open ('X_train_Tot_Acc.txt', 'w').write(str(X_train_Tot_Acc))\n# print(X_train_Tot_Acc)\nprint(X_energy.shape)\n\npca = PCA(n_components=2)\nX_reduced_m1 = pca.fit_transform(X_energy)\n\nprint(f\"Shape of reduced data for plotting: {X_reduced_m1.shape}\")\n\nprint(f\"Variance explained by these 2 PCs: {pca.explained_variance_ratio_}\")\n\n\n(126, 500)\nShape of reduced data for plotting: (126, 2)\nVariance explained by these 2 PCs: [0.10718737 0.08658314]\n\n\n\n\nScatter Plot\n\n\nCode\nfig,axes = plt.subplots()\naxis = axes\n\nscatter = axis.scatter(X_reduced_m1[:, 0], X_reduced_m1[:, 1], c=y_train, cmap='viridis', alpha=0.6, s=10)\nhandles, _ = scatter.legend_elements()\nactivity_labels = [Activity_Classes[i] for i in sorted(Activity_Classes.keys())]\nlegend1 = axis.legend(handles, activity_labels, title=\"Activities\")\naxis.add_artist(legend1)\n\naxis.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\naxis.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\naxis.set_title(\"PCA on Total Acceleration (Signal Energy)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n2. Using TSFEL and then PCA\n\nInstead of feeding raw numbers for PCA, we calculate statistics (features) like Mean, Variance, Entropy, Zero-Crossing Rate, FFT Peak. They are much better at distinguishing overlapping activities rather than raw data (we can see that the 3 activities of standing,;laying and sitting overlaped almost into single point due to ~1g value ).\nSteps:\n\nData Serialization: TSFEL is designed for continuous streams and 2D space. We “unroll” our 3D dataset \\((N, 500, 3)\\) into a long 2D stream \\((N \\times 500, 3)\\) and then use TSFEL’s windowing function to reconstruct the samples.\nFeature Extraction: We extract statistical features independently for each axis (\\(x, y, z\\)). (3 cols of pd dataframe). tsfel does this internally, calculates mean, variance etc for each column and then concatenates 3 cols to one wide row\nStandardization (Critical): We mix features with vastly different physical units (e.g., Variance in \\(m^2/s^4\\) vs. Mean in \\(m/s^2\\)). Without StandardScaler, PCA would be biased towards features with larger numerical magnitudes, ignoring potentially discriminative but smaller-valued features.\n\n\n\n\nCode\nimport tsfel\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\n# prepare data\n# convert (N, 500, 3) -&gt; (N*500, 3)\n# This creates one continuous stream of data.\nX_flat = X_train.reshape(-1, 3)\ndf_stream = pd.DataFrame(X_flat, columns=['acc_x', 'acc_y', 'acc_z'])\n\n\"\"\"\ntsfel config\n - define which features to extract.\n - 'statistical' includes mean, var, kurtosis, etc.\n - 'temporal' includes slope, zero-crossing, etc.\n\"\"\"\n\ncfg = tsfel.get_features_by_domain('statistical') \n# 'temporal' and 'spectral' needs more CPU and time which i dont have\n\n# feature extract\n# window_size=500 and overlap=0 to exactly reconstruct our original samples.\n# fs=50 -&gt; sampling freq (50Hz).\nX_tsfel = tsfel.time_series_features_extractor(\n    cfg, \n    df_stream, \n    fs=50, \n    window_size=500, \n    overlap=0, \n    verbose=0\n)\n\nprint(f\"Feature extraction complete. New shape: {X_tsfel.shape}\")\n# check for NaNs (sometimes features like FFT fail on constant data)\nX_tsfel = X_tsfel.fillna(0)\n\n# standardize\nscaler = StandardScaler()\nX_tsfel_scaled = scaler.fit_transform(X_tsfel)\n\n\n\n\nCode\n# print(X_tsfel.columns)# print names of columns/features\n\n\n\nNow PCA and Plot\n\n\n\nCode\npca_tsfel = PCA(n_components=2)\nX_tsfel_reduced = pca_tsfel.fit_transform(X_tsfel_scaled)\n\nprint(f\"Variance explained (TSFEL): {pca_tsfel.explained_variance_ratio_}\")\n\nfig, ax = plt.subplots()\nscatter = ax.scatter(X_tsfel_reduced[:, 0], X_tsfel_reduced[:, 1], \n                     c=y_train, cmap='viridis', alpha=0.6, s=10)\n\nlegend1 = ax.legend(*scatter.legend_elements(), title=\"Activities\")\nax.add_artist(legend1)\nax.set_title(\"PCA on TSFEL Features (Standardized)\")\nax.set_xlabel(f\"PC1 ({pca_tsfel.explained_variance_ratio_[0]*100:.1f}%)\")\nax.set_ylabel(f\"PC2 ({pca_tsfel.explained_variance_ratio_[1]*100:.1f}%)\")\n\nplt.tight_layout()\nplt.show()\n\n\nVariance explained (TSFEL): [0.53081705 0.19143562]\n\n\n\n\n\n\n\n\n\n\n\n3. PCA on Features provided by the guys who made the dataset (X_train.txt)\n\n\nCode\n# path = '../human+activity+recognition+using+smartphones/UCI HAR Dataset/features.txt'\n\n# with open(path, 'r') as f:\n#       data = f.readlines()\n\npathX=\"../human+activity+recognition+using+smartphones/UCI HAR Dataset/train/X_train.txt\"\npathY=\"../human+activity+recognition+using+smartphones/UCI HAR Dataset/train/y_train.txt\"\n\ndataset_X_train = np.loadtxt(pathX)\ndataset_y_train = np.loadtxt(pathY)\n\nprint(dataset_X_train.shape, dataset_y_train.shape)\n# 561 columns -&gt; of 561 features. each column has value of that feature for all the samples. dataset_y_train has integers for each row range from 1 to 6 denoting which activity class the sample belong to. so now you know what to do :)\npca = PCA(n_components=2)\n#X_train is already in (n_samples, n_features) format, 2D array, so direct pca now\nX_reduced_m3 = pca.fit_transform(dataset_X_train)\nprint(\"X_reduced shape\",X_reduced_m3.shape)\n\nfig,axes = plt.subplots()\naxis=axes\nscatter = axis.scatter(X_reduced_m3[:, 0], X_reduced_m3[:, 1], c=dataset_y_train, cmap='viridis', alpha=0.6, s=10)\nhandles, _ = scatter.legend_elements()\nactivity_labels = [Activity_Classes[i] for i in sorted(Activity_Classes.keys())]\nlegend1 = axis.legend(handles, activity_labels, title=\"Activities\", loc='lower left')\naxis.add_artist(legend1)\naxis.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\naxis.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\naxis.set_title(\"PCA on All 561 Features\")\nplt.tight_layout()\nplt.show()\n\n\n(7352, 561) (7352,)\nX_reduced shape (7352, 2)\n\n\n\n\n\n\n\n\n\n\nWe can see that static and dynamic activities are seperated much more effectively. Also notice that the 3 class of activities in dynamic class are also being seperated nicely. So now we will analyse which features contributed most to the PC1 and PC2 and analyse which features played major role in distiguishing the classes more precisely\n\n\n\nCode\npath = '../human+activity+recognition+using+smartphones/UCI HAR Dataset/features.txt'\n\nfeatures_df = pd.read_csv(path, sep='\\s+', header=None, names=['idx', 'name'])\nfeature_names = features_df['name'].values\n\nprint(f\"Loaded {len(feature_names)} feature names.\")\nprint(pca.components_.shape)\n# analysing weights of features in PCs\n# pca.components_ -&gt; (n_components, n_features) -&gt; (2, 561)\n# row 0 = weights for PC1, row 1 = weights for PC2\n\nprint(\"\\n--- PC1 Interpretation ---\")\n# abs val of weights , no need to direction\npc1_weights = np.abs(pca.components_[0])\n\n# specific trick: argsort gives indices of sorted values. [-5:] takes top 5. [::-1] reverses to descending.\ntop_5_pc1_idx = pc1_weights.argsort()[-5:][::-1]\n\nfor idx in top_5_pc1_idx:\n    print(f\"Feature '{feature_names[idx]}' weight: {pc1_weights[idx]:.4f}\")\n\n\nprint(\"\\n--- PC2 Interpretation ---\")\npc2_weights = np.abs(pca.components_[1])\ntop_5_pc2_indices = pc2_weights.argsort()[-5:][::-1]\n\nfor idx in top_5_pc2_indices:\n    print(f\"Feature '{feature_names[idx]}' weight: {pc2_weights[idx]:.4f}\")\n\n\nLoaded 561 feature names.\n(2, 561)\n\n--- PC1 Interpretation ---\nFeature 'fBodyAccJerk-entropy()-X' weight: 0.1252\nFeature 'fBodyAccJerk-entropy()-Y' weight: 0.1225\nFeature 'tBodyAccJerkMag-entropy()' weight: 0.1206\nFeature 'fBodyAcc-entropy()-X' weight: 0.1202\nFeature 'fBodyAccMag-entropy()' weight: 0.1134\n\n--- PC2 Interpretation ---\nFeature 'tBodyGyroMag-entropy()' weight: 0.1611\nFeature 'fBodyAcc-skewness()-Z' weight: 0.1563\nFeature 'fBodyAcc-kurtosis()-Z' weight: 0.1457\nFeature 'tBodyGyroMag-arCoeff()1' weight: 0.1374\nFeature 'fBodyAcc-meanFreq()-Z' weight: 0.1296\n\n\n&lt;&gt;:3: SyntaxWarning: invalid escape sequence '\\s'\n&lt;&gt;:3: SyntaxWarning: invalid escape sequence '\\s'\n/tmp/ipykernel_21490/3602945237.py:3: SyntaxWarning: invalid escape sequence '\\s'\n  features_df = pd.read_csv(path, sep='\\s+', header=None, names=['idx', 'name'])\n\n\n\n\nAll plots together\n  \n\n\n4. Which one is better from 3 methods?\n\n1st methods of PCA on raw data, ditinguishes the static and dynamic activity pretty well, but does not distinguish intra subactivity classes\n2nd method of PCA on TSFEL features , distinguishes between static and dynamic classes and also intra sub activity of static class, but for dynamix class all 3 are pretty much stacked together. It successfully isolates “Laying” from the other static activities (due to the “Mean” feature capturing the orientation change). However, it struggles to distinguish “Sitting” from “Standing” as their statistical profiles are nearly identical.\n3rd method of PCA on features by dataset providers ditinguishes between static and dynamic classes and also intra sub activity of dynamic class, but for static class all 3 are stacked together\nin the third method we saw that\n\nPC1 was heavily affected by Jerk and Entropy so it sperated static and dynamic classes\nPC2 was heavily affected by gyro and also by freq , so it seperated the intra dynamic subclasses very well. As walking upward and downward has diffrent gyro.\n\nSo even though 3rd method should have better static subclass seperation, tsfel was better at distinguishing static subclasses. (that’s what data is showing atleast :))",
    "crumbs": [
      "Assignment 1 : HAR",
      "Task 1: Exploratory Data Analysis (EDA)"
    ]
  },
  {
    "objectID": "Human Activity Recognition/my-code/Task1.html#question-4-correlation-matrix-for-features-obtained-by-tsfel-and-from-dataset.-identify-the-features-that-are-highly-correlated-with-each-other.-are-there-any-redundant-features",
    "href": "Human Activity Recognition/my-code/Task1.html#question-4-correlation-matrix-for-features-obtained-by-tsfel-and-from-dataset.-identify-the-features-that-are-highly-correlated-with-each-other.-are-there-any-redundant-features",
    "title": "Task 1: Exploratory Data Analysis (EDA)",
    "section": "Question 4: Correlation Matrix for features obtained by TSFEL and from Dataset. Identify the features that are highly correlated with each other. Are there any redundant features?",
    "text": "Question 4: Correlation Matrix for features obtained by TSFEL and from Dataset. Identify the features that are highly correlated with each other. Are there any redundant features?\n\ndataset for tsfel features: X_tsfel\ndataset for dataset providers: dataset_X_train\nlet highly corelated - 0.85 to 0.95\nredundant - corr &gt; 0.95 -&gt; this features are redundant because they provide similar information about the data. keeping both does not add significant value and may lead to overfitting in machine learning models.\n\n\n\nCode\nprint(X_tsfel.shape)\nprint(dataset_X_train.shape)\n\ndf1=pd.DataFrame(X_tsfel)\ndf2=pd.DataFrame(dataset_X_train)\n\ncorr_matrix_1 = df1.corr().abs()\n# print(corr_matrix_1) #93x93\ncorr_matrix_2 = df2.corr().abs()\n# print(corr_matrix_2) #516x516\n\n\n(126, 93)\n(7352, 561)\n\n\n\n\nCode\n# usinf heatmap is redundant as correlation matrix is large\n# so need programatic way to find\n\n# import seaborn as sns\n# sns.heatmap(corr_matrix_1, cmap='rocket')\n# sns.heatmap(corr_matrix_2, cmap='rocket')\n\n\n\n\nCode\n#upper triangle matrix with all zero below 1st diagonal (so that diagonal=0, as self corr=1, we need to ignore that)\ntemp = np.triu(corr_matrix_1,k=1)\n# abs corr values\nindia = np.where((temp &gt;= 0.85) & (temp &lt;= 0.95))\nprint(india[0].shape)\n\nhigh_corr_1 = np.zeros((india[0].shape[0],3))\nfor i in range(india[0].shape[0]):\n    high_corr_1[i] = [india[0][i], india[1][i], temp[india[0][i], india[1][i]]]\n\n#sort\nsorted_indices = np.argsort(high_corr_1[:, 2])[::-1]\n\nhigh_corr_1 = high_corr_1[sorted_indices]\n\nprint(\"Top 10 highly correlated feature pairs in TSFEL features:\")\nfor i in range(10):\n    print(f\"{high_corr_1[i,2]:.4f} : [{X_tsfel.columns[int(high_corr_1[i,0])]} , {X_tsfel.columns[int(high_corr_1[i,1])] }]\")\n\n\n(112,)\nTop 10 highly correlated feature pairs in TSFEL features:\n0.9497 : [acc_x_Median absolute deviation , acc_x_Peak to peak distance]\n0.9489 : [acc_z_Mean absolute deviation , acc_z_Variance]\n0.9471 : [acc_y_Median absolute deviation , acc_y_Standard deviation]\n0.9468 : [acc_x_Interquartile range , acc_x_Variance]\n0.9463 : [acc_y_Mean absolute deviation , acc_y_Peak to peak distance]\n0.9460 : [acc_z_ECDF Percentile_0 , acc_z_Min]\n0.9454 : [acc_x_Peak to peak distance , acc_y_Peak to peak distance]\n0.9428 : [acc_y_ECDF Percentile_0 , acc_y_Min]\n0.9423 : [acc_x_ECDF Percentile_0 , acc_x_Mean]\n0.9421 : [acc_y_Mean absolute deviation , acc_y_Median absolute deviation]\n\n\n\n\nCode\ntemp1=np.triu(corr_matrix_2,k=1)\nindia1 = np.where((temp1 &gt;= 0.85) & (temp1 &lt;= 0.95))\nprint(india1[0].shape)\n\nhigh_corr_2 = np.zeros((india1[0].shape[0],3))\nfor i in range(india1[0].shape[0]):\n    high_corr_2[i] = [india1[0][i], india1[1][i], temp1[india1[0][i], india1[1][i]]]\nsorted_indices = np.argsort(high_corr_2[:, 2])[::-1]\nhigh_corr_2 = high_corr_2[sorted_indices]\nprint(\"Top 20 highly correlated feature pairs in All 561 features:\")\nfor i in range(20):\n    print(f\"{high_corr_2[i,2]:.4f} : [{feature_names[int(high_corr_2[i,0])]} , {feature_names[int(high_corr_2[i,1])]}]\")\n\n\n(13866,)\nTop 20 highly correlated feature pairs in All 561 features:\n0.9500 : [tBodyGyroJerk-iqr()-Z , fBodyGyro-iqr()-Z]\n0.9500 : [tBodyAccJerkMag-mean() , fBodyGyro-mean()-Z]\n0.9500 : [tBodyAccJerkMag-sma() , fBodyGyro-mean()-Z]\n0.9500 : [tBodyAccJerk-std()-X , fBodyGyro-sma()]\n0.9500 : [tBodyAcc-sma() , tBodyAccJerkMag-mad()]\n0.9499 : [tBodyAccJerk-max()-Y , fBodyAccJerk-iqr()-Y]\n0.9499 : [tBodyAcc-mad()-X , fBodyAccJerk-sma()]\n0.9499 : [tBodyAccJerk-std()-Y , tBodyGyroJerk-sma()]\n0.9499 : [tBodyAccJerkMag-mad() , fBodyAcc-iqr()-Y]\n0.9499 : [tBodyAccJerk-iqr()-Y , fBodyAccJerk-entropy()-Y]\n0.9498 : [tBodyGyroMag-mean() , fBodyAcc-mad()-Y]\n0.9498 : [tBodyGyroMag-sma() , fBodyAcc-mad()-Y]\n0.9498 : [fBodyAcc-std()-Y , fBodyAcc-entropy()-X]\n0.9498 : [fBodyAcc-mad()-Y , fBodyAccJerk-entropy()-Z]\n0.9498 : [tBodyAcc-energy()-Y , fBodyAcc-bandsEnergy()-1,24]\n0.9498 : [tBodyAccJerk-std()-Y , fBodyAccJerk-entropy()-X]\n0.9498 : [fBodyAccJerk-sma() , fBodyGyro-mean()-Z]\n0.9497 : [fBodyAccJerk-mad()-X , fBodyGyro-sma()]\n0.9497 : [tBodyAcc-std()-X , fBodyBodyAccJerkMag-entropy()]\n0.9497 : [tBodyGyro-max()-Z , fBodyGyro-mean()-Z]\n\n\n\nRedundant Features\n\n\n\nCode\nindia2= np.where((temp &gt;= 0.95) & (temp &lt;= 1.0))\nprint(india2[0].shape)\nredundant_corr_1=np.zeros((india2[0].shape[0],3))\nfor i in range(india2[0].shape[0]):\n    redundant_corr_1[i] = [india2[0][i], india2[1][i], temp[india2[0][i], india2[1][i]]]\nsorted_indices = np.argsort(redundant_corr_1[:, 2])[::-1]\nredundant_corr_1 = redundant_corr_1[sorted_indices]\nprint(\"Top 20 redundant feature pairs in TSFEL features:\")\nfor i in range(20):\n    print(f\"{redundant_corr_1[i,2]:.4f} : [{X_tsfel.columns[int(redundant_corr_1[i,0])]} , {X_tsfel.columns[int(redundant_corr_1[i,1])] }]\")\n\n\n(69,)\nTop 20 redundant feature pairs in TSFEL features:\n1.0000 : [acc_z_Absolute energy , acc_z_Average power]\n1.0000 : [acc_x_Absolute energy , acc_x_Average power]\n0.9985 : [acc_x_Mean absolute deviation , acc_x_Standard deviation]\n0.9980 : [acc_z_Mean , acc_z_Median]\n0.9980 : [acc_y_Mean , acc_y_Median]\n0.9969 : [acc_z_Mean absolute deviation , acc_z_Standard deviation]\n0.9964 : [acc_y_Mean absolute deviation , acc_y_Standard deviation]\n0.9962 : [acc_y_Histogram mode , acc_y_Median]\n0.9930 : [acc_x_Mean , acc_x_Median]\n0.9929 : [acc_z_Histogram mode , acc_z_Median]\n0.9920 : [acc_y_Histogram mode , acc_y_Mean]\n0.9916 : [acc_z_ECDF Percentile_0 , acc_z_Mean]\n0.9913 : [acc_y_ECDF Percentile_0 , acc_y_Mean]\n0.9899 : [acc_x_Absolute energy , acc_x_Root mean square]\n0.9899 : [acc_x_Average power , acc_x_Root mean square]\n0.9893 : [acc_z_ECDF Percentile_0 , acc_z_Median]\n0.9890 : [acc_x_Mean , acc_x_Root mean square]\n0.9887 : [acc_x_Peak to peak distance , acc_x_Standard deviation]\n0.9871 : [acc_x_Interquartile range , acc_x_Mean absolute deviation]\n0.9869 : [acc_z_Histogram mode , acc_z_Mean]\n\n\n\n\nCode\nindia3 = np.where((temp1 &gt;= 0.95) & (temp1 &lt;= 1.0))\nprint(india3[0].shape)\nredundant_corr_1=np.zeros((india3[0].shape[0],3))\nfor i in range(india3[0].shape[0]):\n    redundant_corr_1[i] = [india3[0][i], india3[1][i], temp1[india3[0][i], india3[1][i]]]\nsorted_indices = np.argsort(redundant_corr_1[:, 2])[::-1]\nredundant_corr_1 = redundant_corr_1[sorted_indices]\nprint(\"Top 20 redundant feature pairs in All 561 features:\")\nfor i in range(20):\n    print(f\"{redundant_corr_1[i,2]:.4f} : [{feature_names[int(redundant_corr_1[i,0])]} , {feature_names[int(redundant_corr_1[i,1])]}]\")\n\n\n(2281,)\nTop 20 redundant feature pairs in All 561 features:\n1.0000 : [fBodyBodyAccJerkMag-mean() , fBodyBodyAccJerkMag-sma()]\n1.0000 : [fBodyBodyGyroJerkMag-mean() , fBodyBodyGyroJerkMag-sma()]\n1.0000 : [tGravityAccMag-mean() , tGravityAccMag-sma()]\n1.0000 : [tBodyAccMag-arCoeff()1 , tGravityAccMag-arCoeff()1]\n1.0000 : [tBodyAccMag-arCoeff()2 , tGravityAccMag-arCoeff()2]\n1.0000 : [tBodyAccMag-arCoeff()3 , tGravityAccMag-arCoeff()3]\n1.0000 : [tBodyAccMag-std() , tGravityAccMag-std()]\n1.0000 : [tBodyAccMag-arCoeff()4 , tGravityAccMag-arCoeff()4]\n1.0000 : [fBodyAccMag-mean() , fBodyAccMag-sma()]\n1.0000 : [tBodyAccMag-energy() , tGravityAccMag-energy()]\n1.0000 : [tBodyAccMag-entropy() , tGravityAccMag-entropy()]\n1.0000 : [tBodyAccMag-iqr() , tGravityAccMag-iqr()]\n1.0000 : [tBodyAccMag-mad() , tGravityAccMag-mad()]\n1.0000 : [tBodyAccMag-max() , tGravityAccMag-max()]\n1.0000 : [tBodyAccMag-min() , tGravityAccMag-min()]\n1.0000 : [tBodyAccMag-sma() , tGravityAccMag-mean()]\n1.0000 : [tBodyAccMag-sma() , tGravityAccMag-sma()]\n1.0000 : [tBodyGyroMag-mean() , tBodyGyroMag-sma()]\n1.0000 : [tBodyAccMag-mean() , tGravityAccMag-sma()]\n1.0000 : [tBodyAccMag-mean() , tGravityAccMag-mean()]",
    "crumbs": [
      "Assignment 1 : HAR",
      "Task 1: Exploratory Data Analysis (EDA)"
    ]
  },
  {
    "objectID": "Human Activity Recognition/Assignment/HAR/ZeroShot_FewShot.html",
    "href": "Human Activity Recognition/Assignment/HAR/ZeroShot_FewShot.html",
    "title": "Notebook to demonstrate Zero shot and Few shot Learning",
    "section": "",
    "text": "Code\nimport pandas as pd \nfrom langchain_groq.chat_models import ChatGroq\n\n\n\n\nCode\n# Groq API and Models \nGroq_Token = \"YOU_API_KEY_GOES_HERE\"  # Do not share this key with anyone\n\ngroq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n\n\nNOTE : DO NOT SHARE THE API KEY WITH ANYONE. DO NOT COMMIT THE API KEY TO GITHUB.\nAlways do a sanity check before committing the code to github. If the key is found in the code, you will be penalized with a 0.5 marks deduction.\n\nZero Shot\n\n\nCode\n# Statement \nsentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n\n# System Prompts \nquery = f\"\"\"\n* You are a sentiment analysis model. \n* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n\nSentence: {sentence}\n\"\"\" \n\n# To use Groq LLMs \nmodel_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\nllm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\nanswer = llm.invoke(query)\n\nprint(answer.content)\n\n\nSentiment label: Neutral\n\nExplanation: The sentence expresses mixed sentiments. The words \"amazing\" and \"happy\" convey a positive sentiment, indicating satisfaction with the product quality and customer service. However, the phrase \"delivery was delayed\" expresses a negative sentiment, indicating dissatisfaction with the delivery experience. Overall, the positive and negative sentiments balance each other out, resulting in a neutral sentiment label.\n\n\n\n\nFew Shot\n\n\nCode\n# Statement \nsentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n\n# System Prompts \nquery = f\"\"\"\n* You are a sentiment analysis model. \n* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n\nHere are few examples:\n1. Sentence: 'The customer service was excellent, and I received my order quickly.'\nSentiment: Positive\n\n2. Sentence: 'The food was bland and the service was slow.'\nSentiment: Negative\n\n3. Sentence: 'The product is okay, but it's not worth the price.'\nSentiment: Neutral\n\nSentence: {sentence}\n\"\"\" \n\n# To use Groq LLMs \nmodel_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\nllm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\nanswer = llm.invoke(query)\n\nprint(answer.content)\n\n\nSentiment: Positive\n\nExplanation: Although the sentence mentions a negative aspect (\"the delivery was delayed\"), the positive sentiments (\"The product quality is amazing\" and \"I am happy with the customer service\") outweigh the negative one, resulting in an overall positive sentiment. The use of the word \"amazing\" and \"happy\" also indicates a strong positive emotion, which contributes to the positive sentiment classification."
  }
]